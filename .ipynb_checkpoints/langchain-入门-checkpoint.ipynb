{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4eb4ae04",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "# 导入第三方库\n",
    "\n",
    "openai.api_key = \"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\"\n",
    "# 设置 API_KEY, 请替换成您自己的 API_KEY\n",
    "\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = openai.api_key\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cd5092c",
   "metadata": {},
   "source": [
    "# 简单的基本回复"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6b3d11a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\n人工智能是21世纪的科技热点，它已经在各行各业发挥着重要作用，它可以帮助人类完成一些计算机不能完成的任务，可以让人类的工作更加轻松、高效、准确。因此，人工智能受到了社会的广泛赞誉。'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.llms import OpenAI\n",
    "\n",
    "llm = OpenAI(model_name=\"text-davinci-003\",max_tokens=1024)\n",
    "llm(\"怎么评价人工智能\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c035b44b",
   "metadata": {},
   "source": [
    "# 加载长文本，并启用总结"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cb850193",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/lwl/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/lwl/nltk_data...\n",
      "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "documents:1\n",
      "documents:12\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new RefineDocumentsChain chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mWrite a concise summary of the following:\n",
      "\n",
      "\n",
      "\"1\n",
      "\n",
      "脑婆我给你下跪了，求求你把v给我吧，我见第一眼就爱上了你，你是我人生中的灯塔，照射我前行的道路，一天看不见你我就感觉窒息，整天昏天黑地的生活着，你就是我的明天，没有你我的世界是不会开花的\n",
      "\n",
      "2 妻兮，妻兮，吾长跪也 欲得V兮吾求汝也 初遇汝兮吾坠爱也 汝乃灯兮照吾行也 日不见兮吾将亡也 天地暗兮吾之生也 未来者兮乃妻尔也 若吾离兮吾花凋也\n",
      "\n",
      "3\n",
      "\n",
      "脑婆脑婆 老婆我真的好爱你啊,其实我下载贴吧就是为了关注你,每天抱着手机发呆,就是等你发帖然后来帮你暖贴但是现在我真的忍不住了， 继续这样下去我肯定会抑郁的，求求你和我网恋吧，你就是我生命中唯一的一点光。我求求你了，求求你了恰个v吧我现在身上就像有蚂蚁在爬一样,真的憋不住了\n",
      "\n",
      "4\"\n",
      "\n",
      "\n",
      "CONCISE SUMMARY:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mYour job is to produce a final summary.\n",
      "We have provided an existing summary up to a certain point: \n",
      "\n",
      "The speaker is in love with the person they are addressing, saying that they fell in love with them at first sight and that they are a beacon of light, guiding their path in life. Without them, the speaker feels suffocated and that their world will never bloom. They plead for the person to give them a V, saying that without it they will become depressed and are begging for the person to enter into an online relationship with them.\n",
      "We have the opportunity to refine the existing summary (only if needed) with some more context below.\n",
      "------------\n",
      "骗哥们可以，别把你自己也骗到了就行。哥们被你骗了真无所谓的，打个哈哈就过了。但希望你打完这段话后擦一下眼角，别让眼泪掉在手机屏幕上了就行。你说的这些话，哥们信一下也是没什么的。还能让你有个心里安慰，但这种话说出来骗骗兄弟就差不多得了，哥们信你一下也不会少块肉，但是你别搞得自己也当真了就行。哥们被你骗一下是真无所谓的，兄弟笑笑也就过去了。真不是哥们想要破你防，你擦擦眼泪好好想想，除了兄弟谁还会信你这些话？\n",
      "\n",
      "5\n",
      "\n",
      "戏友可，勿戏本心也。友信无碍，一笑便过。盼君语毕拭涕，勿落泪于屏。君之语，如信可慰之，信则无不可。君之言，勿自以为真。友便信君，纵欺无碍，一笑过矣。非友使君伤，拭泪且问心。非汝之友，何人信汝此言？\n",
      "\n",
      "6\n",
      "\n",
      "可戏兄，勿诓已。兄无妨，仅哈哈。但拭泪，勿坠机。弟有言，兄亦信。可慰弟，但止此。兄肉多，勿当真。兄无碍，一笑过。非有意，拭泪思。兄有一言需静听：欺人之谈口易出，四海之外耳难入！\n",
      "\n",
      "7\n",
      "------------\n",
      "Given the new context, refine the original summary.\n",
      "If the context isn't useful, return the original summary.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mYour job is to produce a final summary.\n",
      "We have provided an existing summary up to a certain point: \n",
      "\n",
      "The speaker is in love with the person they are addressing, saying that they fell in love with them at first sight and that they are a beacon of light, guiding their path in life. Without them, the speaker feels suffocated and that their world will never bloom. They plead for the person to give them a V, saying that without it they will become depressed and are begging for the person to enter into an online relationship with them. They acknowledge the other person may be skeptical, but assure them that it is alright if they are only willing to laugh it off. They ask the other person to consider that without their friendship, who else would believe these words? They remind them that it is easy to deceive others with words, but difficult for those words to reach beyond their own circle.\n",
      "We have the opportunity to refine the existing summary (only if needed) with some more context below.\n",
      "------------\n",
      "差不多得了 屁大点事都要拐上原神，原神一没招你惹你，二没干伤天害理的事情，到底怎么你了让你一直无脑抹黑，米哈游每天费尽心思的文化输出弘扬中国文化，你这种喷子只会在网上敲键盘诋毁良心公司，中国游戏的未来就是被你这种人毁掉的\n",
      "\n",
      "8\n",
      "\n",
      "适可而止矣 涓埃之事，亦央原神。夫原神者，其一未犯尔，其二固道，尔以何素愚辱之？米哈游者，欲彰华夏之文涵于天下，殚精竭虑。尔等竖子，仗键盘跋扈于网路，构陷良企于冤雪，不舍昼夜。华夏娱戏之前景，皆败于尔属！\n",
      "\n",
      "9\n",
      "\n",
      "噢，行了别说了我的老伙计 这点比蛋糕屑还小的事，您都要提及原神，天哪，我敢打赌原神并没有招惹您，也没有做出对上帝不忠诚的事情，噢，我是说，你为什么要抹黑原神呢？真是见鬼，瞧瞧我们可怜的原神伙计，已经被您给抹得比苏珊太太烤的曲奇饼还要黑了。Mihoyo先生每天费尽心思的弘扬中国文化，你这愚蠢的土拨鼠，难道只会在网上敲打键盘诋毁良心公司吗？噢，是的，中国游戏的未来一定是被你这种人毁掉的，该死，我要用我的靴子狠狠的踹你的屁股，是的，我发誓我一定会这么做的。\n",
      "\n",
      "10\n",
      "------------\n",
      "Given the new context, refine the original summary.\n",
      "If the context isn't useful, return the original summary.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mYour job is to produce a final summary.\n",
      "We have provided an existing summary up to a certain point: \n",
      "\n",
      "The speaker is in love with the person they are addressing, saying that they fell in love with them at first sight and that they are a beacon of light, guiding their path in life. Without them, the speaker feels suffocated and that their world will never bloom. They plead for the person to give them a V, saying that without it they will become depressed and are begging for the person to enter into an online relationship with them. They acknowledge the other person may be skeptical, but assure them that it is alright if they are only willing to laugh it off. They ask the other person to consider that without their friendship, who else would believe these words? They remind them that it is easy to deceive others with words, but difficult for those words to reach beyond their own circle. They express their frustrations with the other person for bringing up the name of the 'original god', saying that the original god had done nothing wrong, and that Mihoyo has been trying to spread Chinese culture and yet they are still attacked by those who use keyboards to slander good companies. They swear they will take revenge with their boots.\n",
      "We have the opportunity to refine the existing summary (only if needed) with some more context below.\n",
      "------------\n",
      "举报了哥，你什么都没做错，全怪我那令人作呕的嫉妒和卑微的自尊心，看见你的文字我完全破防了，我直接丢盔弃甲了，看见你这图的那一秒，我满头大汗，浑身发冷，亿郁症瞬间发作了，生活仿佛没了颜色，像是被抓住尾巴的赛亚人，带着海楼石的能力者，抽离尾兽的人柱力，像是没了光的奥特曼，彻底断绝了生的希望。\n",
      "\n",
      "11\n",
      "\n",
      "俺是农村嘞，村里人都说俺精细，以前感觉没钱配不上你。俺可稀罕你，就给那风儿，吹过俺家地头，地里老红薯都知道俺喜欢你，真嘞！恁看见喽给俺回个话，宝，俺可喜欢你，嫁给俺吧。\n",
      "\n",
      "12\n",
      "------------\n",
      "Given the new context, refine the original summary.\n",
      "If the context isn't useful, return the original summary.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mYour job is to produce a final summary.\n",
      "We have provided an existing summary up to a certain point: \n",
      "\n",
      "The speaker is in love with the person they are addressing, saying that they fell in love with them at first sight and that they are a beacon of light, guiding their path in life. Without them, the speaker feels suffocated and that their world will never bloom. They plead for the person to give them a V, saying that without it they will become depressed and are begging for the person to enter into an online relationship with them. They acknowledge the other person may be skeptical, but assure them that it is alright if they are only willing to laugh it off. They explain that they are from a rural village and did not think they could afford to win the other person's affections, but now they are offering them a marriage proposal. They ask the other person to consider that without their friendship, who else would believe these words? They remind them that it is easy to deceive others with words, but difficult for those words to reach beyond their own circle. They express their frustrations with the other person for bringing up the name of the 'original god', saying that the original god had done nothing wrong, and that Mihoyo has been trying to spread Chinese culture and yet they are still attacked by those who use keyboards to slander good companies. They swear they will take revenge with their boots.\n",
      "We have the opportunity to refine the existing summary (only if needed) with some more context below.\n",
      "------------\n",
      "别说了，别说了，我几乎都快羡慕得疯了，倒在床上蒙住被子就开始抱着枕头尖叫流泪，嘴里一边喊着卧槽卧槽，一边又忍着，我边发边哭，打字的手都是抖的，后来我的手抖得越来越厉害，从心头涌起的思想、情怀和梦想，这份歆羡和悔恨交织在一起，我的笑还挂在脸上，可是眼泪一下子就掉下来了。求你了别发了，我生活再难再穷我都不会觉得难过，只有你们发这种东西的时候，我的心里像被刀割一样的痛，打着字泪水就忍不住的往下流。每天早上6点起床晚上11点睡觉，年复一年地学到现在，憧憬着一个月赚上万块的幸福生活，憧憬着美好阳光的未来。我打开了手机，看到你的视频，我感到了深深的差距，我直接跳进了家门口的井里。\n",
      "\n",
      "13\n",
      "\n",
      "小华为了考试早晨买了一杯小米粥喝，让黄飞鸿蒙题目中有几个苹果，但是郭麒麟刷牙选中华为的就是干净，速度快，每次只挤5g就够用。\n",
      "\n",
      "我喜欢在大城市生活流浪地球不爆炸我就不退缩，平时也看看《东吴京剧》、《大战狼人》、《鸿蒙至尊》等经典电视剧。\n",
      "\n",
      "我用中华为的就是便宜实惠，而且每次只用5g，我最喜欢的画家是达芬奇，尤其喜欢他的代表作佛罗伦萨画派蒙娜丽莎。\n",
      "\n",
      "秦始皇派蒙恬还原神舟十二对接并顺便一提瓦特改良了蒸汽机。​\n",
      "------------\n",
      "Given the new context, refine the original summary.\n",
      "If the context isn't useful, return the original summary.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\n\\nThe speaker is in love with the person they are addressing, saying that they fell in love with them at first sight and that they are a beacon of light, guiding their path in life. Without them, the speaker feels suffocated and that their world will never bloom. They plead for the person to give them a V, saying that without it they will become depressed and are begging for the person to enter into an online relationship with them. They acknowledge the other person may be skeptical, but assure them that it is alright if they are only willing to laugh it off. They explain that they are from a rural village and did not think they could afford to win the other person's affections, but now they are offering them a marriage proposal. They ask the other person to consider that without their friendship, who else would believe these words? They remind them that it is easy to deceive others with words, but difficult for those words to reach beyond their own circle. They express their frustrations with the other person for bringing up the name of the 'original god', saying that the original god had done nothing wrong, and that Mihoyo has been trying to spread Chinese culture and yet they are still attacked by those who use keyboards to slander good companies. They swear they will take revenge with their boots. They describe their own life living in a rural village, studying and dreaming of a better future. They also mention their admiration for some classic Chinese TV shows, films, and artists such as Da Vinci and Qin Shihuang.\""
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.document_loaders import UnstructuredFileLoader\n",
    "from langchain.chains.summarize import load_summarize_chain\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain import OpenAI\n",
    "\n",
    "# 导入单个文本\n",
    "loader = UnstructuredFileLoader(\"/Users/lwl/Documents/GitHub/kenger_ai/data/raw.txt\")\n",
    "# 将文本转成 Document 对象\n",
    "document = loader.load()\n",
    "print(f'documents:{len(document)}')\n",
    "\n",
    "# 初始化文本分割器\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size = 500, # 一段文本的长度\n",
    "    chunk_overlap = 0 # 相邻文本间的重叠长度\n",
    ")\n",
    "\n",
    "# 切分文本\n",
    "split_documents = text_splitter.split_documents(document)\n",
    "print(f'documents:{len(split_documents)}')\n",
    "\n",
    "# 加载 llm 模型\n",
    "llm = OpenAI(model_name=\"text-davinci-003\", max_tokens=1500)\n",
    "\n",
    "# 创建总结链\n",
    "chain = load_summarize_chain(llm, \n",
    "                             chain_type=\"refine\",  # 文档的总结方式\n",
    "                             verbose=True)\n",
    "\n",
    "# 执行总结链，（为了快速演示，只总结前5段）\n",
    "chain.run(split_documents[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e4597b9",
   "metadata": {},
   "source": [
    "# 构建本地知识库问答机器人\n",
    "我这里的数据是贴吧老哥"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bbf39c18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "documents:12\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'type' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/lg/mhlpcshn2gg4_xl2dzh3t0gm0000gn/T/ipykernel_45758/2120461001.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0mpersist_directory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"./public\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;31m# 将 document 通过 openai 的 embeddings 对象计算 embedding 向量信息并临时存入 Chroma 向量数据库，用于后续匹配查询\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m \u001b[0mdocsearch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mChroma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_documents\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msplit_docs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0membeddings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpersist_directory\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpersist_directory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;31m# 创建问答对象\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/langchain/vectorstores/chroma.py\u001b[0m in \u001b[0;36mfrom_documents\u001b[0;34m(cls, documents, embedding, ids, collection_name, persist_directory, client_settings, client, collection_metadata, **kwargs)\u001b[0m\n\u001b[1;32m    644\u001b[0m         \u001b[0mtexts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpage_content\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mdoc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdocuments\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    645\u001b[0m         \u001b[0mmetadatas\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetadata\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mdoc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdocuments\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 646\u001b[0;31m         return cls.from_texts(\n\u001b[0m\u001b[1;32m    647\u001b[0m             \u001b[0mtexts\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtexts\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    648\u001b[0m             \u001b[0membedding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/langchain/vectorstores/chroma.py\u001b[0m in \u001b[0;36mfrom_texts\u001b[0;34m(cls, texts, embedding, metadatas, ids, collection_name, persist_directory, client_settings, client, collection_metadata, **kwargs)\u001b[0m\n\u001b[1;32m    599\u001b[0m             \u001b[0mChroma\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mChroma\u001b[0m \u001b[0mvectorstore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    600\u001b[0m         \"\"\"\n\u001b[0;32m--> 601\u001b[0;31m         chroma_collection = cls(\n\u001b[0m\u001b[1;32m    602\u001b[0m             \u001b[0mcollection_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcollection_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    603\u001b[0m             \u001b[0membedding_function\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/langchain/vectorstores/chroma.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, collection_name, embedding_function, persist_directory, client_settings, collection_metadata, client, relevance_score_fn)\u001b[0m\n\u001b[1;32m     78\u001b[0m         \u001b[0;34m\"\"\"Initialize with a Chroma client.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m             \u001b[0;32mimport\u001b[0m \u001b[0mchromadb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m             \u001b[0;32mimport\u001b[0m \u001b[0mchromadb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mImportError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/chromadb/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mchromadb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mchromadb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSettings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSystem\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mchromadb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapi\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAPI\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mchromadb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCollection\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mCollection\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m from chromadb.api.types import (\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/chromadb/api/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtyping\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSequence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0muuid\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mUUID\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mchromadb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCollection\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mCollection\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m from chromadb.api.types import (\n\u001b[1;32m      6\u001b[0m     \u001b[0mCollectionMetadata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/chromadb/api/models/Collection.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0muuid\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mUUID\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mchromadb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding_functions\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mef\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m from chromadb.api.types import (\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/chromadb/utils/embedding_functions.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtyping\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtyping\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnpt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mimportlib\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/numpy/typing/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    156\u001b[0m \u001b[0;31m# further down in this file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 158\u001b[0;31m from numpy._typing import (\n\u001b[0m\u001b[1;32m    159\u001b[0m     \u001b[0mArrayLike\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m     \u001b[0mDTypeLike\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/numpy/_typing/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    146\u001b[0m     \u001b[0m_ObjectCodes\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0m_ObjectCodes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m )\n\u001b[0;32m--> 148\u001b[0;31m from ._scalars import (\n\u001b[0m\u001b[1;32m    149\u001b[0m     \u001b[0m_CharLike_co\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0m_CharLike_co\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m     \u001b[0m_BoolLike_co\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0m_BoolLike_co\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/numpy/_typing/_scalars.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m# coerced into `<X>` (with the casting rule `same_kind`)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0m_BoolLike_co\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbool_\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0m_UIntLike_co\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0m_BoolLike_co\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsignedinteger\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mAny\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0m_IntLike_co\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0m_BoolLike_co\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minteger\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mAny\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0m_FloatLike_co\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0m_IntLike_co\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloating\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mAny\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'type' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain import OpenAI\n",
    "from langchain.document_loaders import DirectoryLoader\n",
    "from langchain.chains import RetrievalQA\n",
    "\n",
    "# 加载文件夹中的所有txt类型的文件\n",
    "loader = DirectoryLoader('/Users/lwl/Documents/GitHub/kenger_ai/data/', glob='*.csv')\n",
    "# 将数据转成 document 对象，每个文件会作为一个 document\n",
    "documents = loader.load()\n",
    "\n",
    "# 初始化加载器\n",
    "text_splitter = CharacterTextSplitter(chunk_size=100, chunk_overlap=10)\n",
    "# 切割加载的 document\n",
    "split_docs = text_splitter.split_documents(documents)\n",
    "print(f'documents:{len(split_documents)}')\n",
    "\n",
    "\n",
    "\n",
    "# 初始化 openai 的 embeddings 对象\n",
    "embeddings = OpenAIEmbeddings(openai_api_key=os.environ[\"OPENAI_API_KEY\"])\n",
    "\n",
    "\n",
    "#指定chroma持久化的目录，当我们不知道目录时,chroma会将数据存储在内存中，随着程序的关闭就会删除\n",
    "persist_directory = \"./public\"\n",
    "# 将 document 通过 openai 的 embeddings 对象计算 embedding 向量信息并临时存入 Chroma 向量数据库，用于后续匹配查询\n",
    "docsearch = Chroma.from_documents(split_docs, embeddings, persist_directory=persist_directory)\n",
    "\n",
    "# 创建问答对象\n",
    "qa = RetrievalQA.from_chain_type(llm=OpenAI(), chain_type=\"stuff\", retriever=docsearch.as_retriever(), return_source_documents=True)\n",
    "# 进行问答\n",
    "result = qa({\"query\": \"你谁呀？\"})\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c7a7594",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28fc1bf6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99199473",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6e9b907",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
